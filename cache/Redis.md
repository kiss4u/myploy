#  Redis

[TOC]

## 基本数据类型

| 类型                 | 简介                                                    | 特性                                                         | 场景                          | 实现原理                                                     |
| :------------------- | :------------------------------------------------------ | :----------------------------------------------------------- | :---------------------------- | ------------------------------------------------------------ |
| String(字符串)       | 二进制安全                                              | 可以包含任何数据，比如jpg图片或者序列化的对象，一个键最大能存储512M | ---                           |                                                              |
| Hash(字典)           | 键值对集合                                              | 适合存储对象,并且可以像数据库中update一个属性一样只修改某一项属性值(Memcached中需要取出整个字符串反序列化成对象修改完再序列化存回去) | 存储、读取、修改用户属性      | 数组加链表，key出现hash碰撞，元素用链表链接<br/>rehash就是随着存储变化进行扩容缩容，一次性rehash比较耗时，采用渐进式hash，在rehash时保留新旧两个hash结构，在后续定时任务或rehash过程中逐步的将旧数据转移到新hash中 |
| List(列表)           | 链表(双向链表)                                          | 增删快,提供了操作某一段元素的API                             | 1、消息队列 2、数据分页       | 数据较少的情况使用连续的内存空间存储，即ziplist，数据量大多个ziplist连成quickList |
| Set(集合)            | 哈希表实现，元素不可重复                                | 增删查复杂度O(1) ，提供了交集、并集、差集等操作              | 1、共同好友、喜好等 2、访问量 |                                                              |
| Sorted Set(有序集合) | 将Set中的元素增加一个权重参数score，元素按score有序排列 | 集合内元素有序                                               | 1、排行榜 2、延迟消息队列     | skipList                                                     |

## 高级数据结构

### GeoHash

>1、坐标经纬度，地球映射成一个平面，通过不同的切割法（例：二刀法，横切一下竖切一下，切割出四块分别标记00,01,10,11，然后每小块再继续切割）得出一串二进制整数
>
>2、geodist、geopos
>
>ps：zset存储，单key数据量大建议单独集群，可继续按城市大区等拆分

### BitMap

>1、byte数组，每位用0/1填充，1代表该下标代表的元素存在
>
>2、bitcount、bitfield命令

### HyperLogLog

> 1、提供不精确去重功能，最大占用内存12KB
>
> 2、使用16384个桶，每个桶6bit
>
> 3、通过计算每个桶末尾开始连续为0的最大位数位maxbit，
>
> 4、2的maxbit方，多个结果做平均数，预估数量

### BloomFilter

> 1、底层是一个大型位数组，通过多个不同的无偏hash函数计算，将计算结果对数组长度取模运算得到一个位置，设置设成1
>
> 2、如果有任意一个hash结果的对应位数存储的不是1，则说明该元素不存在，hash算法越多越准确
>
> 3、可以设置initsize来降低误差，但是相应会增加占用空间，就是加大数组的长度

## PubSub

### 缺点

>1、已淘汰，消息不是持久化，某个消费者如果挂掉，重新连接不会接收到以前的信息

## Stream

> 

## 利用redis实现限流

### zset实现

> zremrangeByScore(key, 0, now-limit) 每次行为发生，只保留滑动窗口期间的记录，统计数量比较

### 漏斗 redis-cell

>1、初始容量，例15，超过15次才开始做限流
>
>2、流水速率，例每60秒最多20次
>
>3、剩余容量
>
>4、上一次漏水时间

## 模糊查询

### keys

>遍历所有key，时间复杂度O(n)，串行执行可能造成服务器卡顿

### scan

>1、复杂度也是O(n)，但是使用游标，每次遍历一批数据返回游标，不会造成卡顿
>
>2、支持设置每次遍历数量limit，结果可能会出现重复数据
>
>3、返回结果为空不代表结束，要看游标是否为0
>
>4、遍历期间数据变化，不确定会不会被扫描到

## 通用规则

### create if not exist

> 不存在即创建

### drop if no element

> 元素为空即删除

## 底层结构

### key存储

> 1、所有的key都存在一个大的hashmap中，扩容数组大小加倍
>
> 2、scan命令遍历就是遍历数组下标，设置limit返回数量不确定是因为每个槽位置挂链表情况不同

### SkipList

> 多级链表，新元素随机决定能深入多少层，元素越多，到最顶层的几率越大

### SDS（Simple Dynamic String）

>redis底层用C语言实现，它没有用C语言的字符类型，自己实现了一套SDS结构

```c
struct sdshdr {
    // 当前字符串长度
	int len;
    // 剩余可用长度
	int free;
    // 实际存储字符串
	char buf[];
}
```

> reids的key是一个SDS值，value如果是String类型，实际存储的也是SDS，非String是long类型

#### 与C字符串的区别

##### 1、计数方式

>C字符串从前向后遍历，直到空字符（\0）为止
>
>sds自己维护了len长度

##### 2、长度变更

>C字符串做修改比如拼接，如果没计算好内存，会产生溢出
>
>sds通过free判断剩余空间是否足够，如果不够会进行扩容

##### 3、减少修改时内存重新分配次数

> 每次修改后，预留free空间，避免频繁扩展；（如果多次未用到会回收）

##### 4、二进制安全

> C通过空字符（\0）判断长度，很多数据类型会穿插空字符比如说图片视频音频等，sds使用len避免了这种误判

## 单线程模型

>IO操作多线程，命令放入队列，文件事件处理器单线程执行消费
>
>1、纯内存操作
>
>2、多路复用
>
>3、单线程避免上下文切换

## 通信协议

### RESP(redis serialization protocol)

> 格式简单（前缀 + 长度），解析性能好
>
> 1、单行字符串 + 开头
>
> 2、多行字符串 $ 开头，后跟字符串长度
>
> 3、整数值 ：开头，后跟整数字符串类型
>
> 4、错误消息 - 开头
>
> 5、数组 * 开头，后跟数组长度

## 过期策略

> 1. 定时删除：设置每隔n秒执行一次，随机抽取设置了过期时间的key，检查是否过期删除	
>
> 2. 惰性删除：获取key时，检查是否存在过期时间，如过期则删除

## 淘汰机制

> 定时删除和惰性删除都没触碰，达到最大存储空间，有新key加入
>
> 2. allkeys-lru：全量key中，移除最少使用的
> 3. allkeys-random：全量key中，随机抽取移除
> 4. volatile-lru：在设置了过期时间的key中，移除最少使用的
> 5. volatile-random：在设置了过期时间的key中，随机抽取移除
> 6. volatile-ttl：在设置了过期时间的key中，移除剩余时间最短的
> 7. noeviction：不删除，直接返回错误

## 手写LRU？

> LinkedHashMap，按访问时间排序

## ReHash

当hash表保存的数据过多或过少时，对哈希表的大小进行相应的扩展或者收缩

>1、为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个哈希表
>
>2、维持索引计数器变量rehashidx，并将它的值设置为0，表示rehash开始
>
>3、每次对字典执行增删改查时，将ht[0]的rehashidx索引上的所有键值对rehash到ht[1]，将rehashidx值+1
>
>4、当ht[0]的所有键值对都被rehash到ht[1]中，程序将rehashidx的值设置为-1，表示rehash操作完成

## 持久化

### RDB

> config配置 save 60 10000
>
> 1、快照形式，全量备份，记录内存数据二进制序列化内容
>
> 2、同步回写：save
>
> 3、异步回写：bgsave，新建一个子进程执行

#### COW(copy on write)

> fork一个子进程执行，如果父进程在执行更改操作，就复制出一个内存页执行

### AOF

>config配置 append-only on
>
>1、日志形式，append-only增量备份，记录数据变化的指令文本
>
>2、先执行指令，成功了再记录日志
>
>3、命令会先写到os cache，每隔1秒调用下fsync，强制从操作系统缓存写磁盘

#### fsync

> always、everysec、no

#### AOF文件瘦身

>当aof文件过大时，会开启一个子进程对当前内存转化为redis指令，rewrite一个新的aof文件，然后再将期间的发生的命令增量更新到新文件中

### 数据恢复

> 1、持久化 + 云备份，RDB或AOF文件做冷备
>
> 2、优先使用aof进行指令重放恢复，通常不会使用rdb文件恢复，会丢失大量数据

#### 4.0后支持混合持久化

> 1、先恢复rdb部分内容，再重放增量的aof日志
>
> 2、RDB和AOF rewrite不会同时工作，当进行RDB时，如果手动命令bgrewriteaof，会排队等待执行

### 企业级备份方案

> 1、每小时copy一份RDB文件，保留最近48小时内的
>
> 2、每天copy一份当日最新的RDB文件，保留最近一个月的
>
> 3、每天0点将备份文件复制到云服务上

## 管道

> 客户端通过改变读写指令的顺序，提高性能
>
> 1、写请求，数据写到本地内核的发送缓存中即返回
>
> 2、读请求，数据从本地内核接收缓存中取回，如果缓存中是空的，则等待server端数据到来
>
> 3、连续的write无开销，等待之后第一个read的网络开销，后续的读操作都直接从本地缓存拿结果

## 事务

> 1、只满足隔离性，不具备原子性，命令出现错误一样继续执行

### 并发操作

#### 分布式锁

#### watch实现乐观锁 

## 在线扩容

### ~~Pre-Sharding~~

>Pre-Sharding方法是将每一个台物理机上，运行多个不同端口的Redis实例。
>
>假如有三个物理机，每个物理机运行三个Redis实例，那么我们的分片列表中实际有9个Redis实例，当我们需要扩容时，增加一台物理机，步骤如下：
>
>A.   在新的物理机上运行Redis-Server；
>
>B.   该Redis-Server从属于(slaveof)分片列表中的某一Redis-Server（假设叫RedisA）；
>
>C.   等主从复制(Replication)完成后，将客户端分片列表中RedisA的IP和端口改为新物理机上Redis-Server的IP和端口；
>
>D.   停止RedisA。
>
>这样相当于将某一Redis-Server转移到了一台新机器上。Prd-Sharding实际上是一种在线扩容的办法，但还是很依赖Redis本身的复制功能的，如果主库快照数据文件过大，这个复制的过程也会很久，同时会给主库带来压力。所以做这个拆分的过程最好选择为业务访问低峰时段进行。

## 主从同步方式

slave定时检查是否跟master连接，如果master配置了需要认证口令，发送口令过去校验，首次连接执行全量复制，后续进行增量复制

![image-20210518121006142](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210518121006142.png)

#### backlog

> mater中维护backlog，保存从节点的复制流水，当发生断开重连时，根据offset从backlog中取出丢失的数据重传

#### offset

>master和slave都维护一个offset（slave定时上报，master保存每个slave的）

#### master run id

> 通过对比run id判断主节点状态（比如说master重启或数据恢复到1小时之前的dump文件），发现不一致则执行全量的复制

#### psync

> slave节点发送psync runid offset命令给master节点，master来判断是进行全量复制还是增量复制

### 增量同步

> 指令记录在内存buffer中，定长的环形数组，通过偏移量标明同步到哪里，当新增大于同步速度时，可能会出现数据被覆盖，此时会用到快照同步

### 快照同步

> 1、slave首次连接，master向slave发送全量数据
>
> 2、当增量同步指令流无法支持数据更新时，发送rdb文件，支持断点续传

### 无盘复制

> 配置参数开启后，master的RDB文件直接边生成边通过socket发送给slave

## 主从互发心跳

>master每隔10秒发一次，slave每隔秒发一次

## 高可用

> 主从节点，读写分离
>
> 多主水平扩容，cluster模式
>
> 哨兵模式，主备切换

## 数据延迟、脑裂问题导致的数据不一致

> min-replicas-to-write 1	最少的salve节点为1个，第二个参数表示
>
> min-replicas-max-lag 10	数据复制和同步的延迟不能超过10秒
>
> 如果发现数据复制延迟或脑裂，原master会在客户端写入操作的时候拒绝请求，避免大量数据丢失。

## 哨兵机制

高可用最少3节点

> 主观宕机（sdown）：自己认为挂了
>
> 客观宕机（odown）：quorum数量的哨兵都认为挂了，需要有majority数量的哨兵节点存活才可进行选举

### 互相发现机制

> 各哨兵会定时向监听的master+slave集群的指定channel发送一条消息，哨兵们通过订阅这个channel感知其他的存在

### 选举规则

> 1、先看slave跟master断开的时长，越长越不适合
>
> 2、然后根据slave优先级（配置的）排序
>
> 3、优先级相同，看同步的offset位置，offset越大说明当前slave下数据越新
>
> 4、看记录的run id，越小越新

### 主从切换

> 1、执行切换的哨兵，会从要切换为master的节点得到一个config-epoch，即一个version号；如果该哨兵执行切换失败，其他哨兵在failover-timeout后继续尝试切换，并获得新的version
>
> 2、切换完成后，会在本地更新生成最新配置，将version发布到channel中，其他哨兵通过对比version来判断本地的配置是否需要刷新

### 哨兵下线

>1、停止目标sentinel进程
>
>2、其他sentinel机器上执行reset *，重置master信息
>
>3、在所有sentinel上执行sentinel master mastername，检查哨兵数量是否一致

### slave下线

> 在所有sentinel上执行sentinel reset mastername

## 集群化方案

实现分布式存储

### cluster

> 1、slot划分16383个，每个节点都分布slot，会用key通过crc16算法得出一个值取模，访问对应节点

#### 水平扩展master/slave节点

redis cluster模式下，不建议物理的读写分离，建议通过增加master来进行水平扩容，并且redis单机内存6G，8G，防止fork子进程太慢。 通过新搭建一个master实现扩容： 1. 搭建一台新的master并且启动； 2. 加到集群上去：使用命令redis-trib.rb add-node 本机ip:port 要连的ip:port 3. 检查是否添加集群成功：使用命令 redis-trib.rb check 要连的ip:port 4. 新redis节点成为master成功 但是没有hash lot 5. 迁移其他集群上的hash lot到新master节点上，也就是reshard数据：使用命令 redis-reib.rb reshard 要连的ip:port 6. 计算迁移多少过去（把之前3个master上的16384个平均分成4份，一份给新节点）：16384/4 = 4096个 7. 输入原master nodeid，意思将这三个上的hashlot 转移给新节点。 8. 使用check命令查看。 9. 新建slave，连到新的master上。也是使用上面的redis-trib.rb 命令，后面跟一些参数。

#### slave自动迁移

> 冗余的slave自动迁移到其他无slave的节点上

#### 选举规则

> 跟哨兵的选举规则类似；判断节点宕机，多个节点确认，pdown 转 down；从宕机的节点所有slave节点中，选举一个转化为master节点
>
> 1、节点过滤。检查slave节点和master节点断开连接的时间，如果超过cluster-node-timeout * cluster-slave-validity-factor，不会被选中切换
>
> 2、节点选举。根据offset判断选中的优先级，所有master开始投票，半数以上投票给某个slave节点，选举通过开始切换

### codis

> 1、slot默认取值1024，可手工增大，key通过算法得出一个值取模，余数对应一个redis实例
>
> 2、需要额外的proxy服务来存储槽和节点的对应关系

## 通信方式

### 集中式

> 独立的服务来存储元数据

### gossip

>每个节点都存储元数据，相互同步
>
>meet
>
>ping/pong
>
>fail

### jedis smart 模式

> 客户端本地维护一份slot到node的映射缓存，减少通过cluster来计算slot重定向

