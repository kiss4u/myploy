[TOC]

## Java

### 1、基础

#### HashMap底层原理

> 底层是数组+链表实现的，key通过 （n - 1) & hash计算出下标位置，如果该位置冲突，就以链表的形式存储；
>
> 当这个链表长度大于等于8时，转化为红黑树，小于等于6时，还原成链表
>
> 因为红黑树平均查找长度是log(n)，长度为8时平均查找长度为3，使用链表平均查找长度为4
>
> 存在差值7，是为了避免频繁插入删除，导致树和链表来回转换

红黑树

> 深度平衡的二叉树，深度差不超过1，发生偏移会左旋右旋调整

#### HashMap1.7到1.8做了哪些优化

> 1、红黑树
>
> 2、扩容方式

HashMap扩容时为什么是2的n次幂

> Hashmap计算存储位置时，使用了(n - 1) & hash，只有当容量n为2的幂次方，n-1的二进制会全为1，位运算时可以充分散列，避免不必要的哈希冲突

#### HashMap、HashTable、ConcurrentHashMap

> HashMap是非线程安全的
>
> HashTable是线程安全的，加synchronized，效率差
>
> ConcurrentHashMap是线程安全的，通过划分成16个小的map对象，每个里面维护一个锁变量，多线程来调用的时候分配一个空闲的对象使用，如果都被占用就通过cas来尝试获取

#### ThreadLocal、InheritThreadLocal原理

> ThreadLocal是每个线程都维护一个自己的ThreadLocalMap，key是这个线程对象，value是存储的值，实现多线程的变量安全
>
> InheritThreadLocal，可以被子线程继承，当创建子线程时，先判断当前线程是否存在InheritThreadLocal，如果存在就复制一份

#### 使用ThreadLocal时要注意什么

> 一般用static修饰（可以理解成工具类），使用完后要把值移除，否则容易发生内存泄漏（使用线程池时）
>
> 只要这个Thread存活，这个ThreadLocal对象就不会被回收，那么里边的值也会一直存在

#### LinkedHashMap

>支持插入顺序的map结构

#### 基于LinkedHashMap实现LRU

> 继承LinkedHashMap，然后重写一下 方法淘汰超过指定size的元素

##### 手写一个LRU



#### 如何开启一个新线程

> 1、继承Thread类
>
> 2、实现runnable方法

#### Thread调用run和start有什么区别

> 调用run不会启用新线程
>
> start才开启一个新线程

### 2、并发

#### volatile关键字作用

> 保证内存可见性，每次读都从主内存获取，写完放回主内存，不使用二级缓存的数据
>
> 防止指令重排，比如说单例模式的双重校验锁，定义singleton变量时用volatile修饰，防止new时出现指令重排，导致创建多个实例

#### sychronized关键字解析

> 利用对象头的标识位来进行加锁，实现线程安全
>
> 第一个线程来加锁时，会加上偏向锁，标明已经有一个线程在用，没有竞争不用cas；
>
> 当有其他线程来获取时，会把偏向锁升级成轻量级锁，这个时候多个线程时间分片使用，竞争不激烈，不用cas；
>
> 当出现一次竞争冲突时，会把轻量锁升级成重量级锁，每次都cas获取

#### ReentrantLock

> 独占锁

#### ReentrantReadWriteLock

> state 高低位分别代表
>
> 读锁
>
> 写锁
>
> 

#### SmaphoreLock





#### CAS和AQS原理

> cas 比较交换，当前值和传入值是否一致，如果一致就修改成目标值
>
> AQS抽象同步队列，lock的底层实现
>
> 当cas获取失败时，会把线程放入AQS的队列中，等待下次获取
>
> 默认是非公平的，尝试获取失败后变公平锁，放入队列
>
> lock支持多个condition的，当相同的condition加锁，会以链表的形式记录，然后等待siganl拿出放到AQS队列中竞争

#### Random弊端及ThreadLocalRandom原理

> random需要依靠一个随机因子来生成随机数，当多线程情况下，随机会不断变化，每次都需要cas来获取，并发高时低效
>
> ThreadLocalRadom，每个线程都使用自己的算法因子，不存在竞争

#### LongAdder原理

> 一个基准值 + 数组形式，无并发时直接修改基准值，当有并发时，获取数组位修改，查询时计算基准值+数组值的和
>
> 还有其他类似的类比如说LongActumator，支持自定义运算方式

#### AtomicLong

> volatile修饰，然后靠cas来维护

#### CountDownLatch、Semaphore、CycleBarrier

>countdownlatch 计数器，初始化设置一个值，然后调用减，当减为0时，线程组恢复running
>
>semaphore 信号量 累加形式
>
>cyclebarrier 回环屏障，支持重置使用

### 3、线程池

#### 使用线程池的好处

> 可以做线程隔离，避免应用的所有线程都被阻塞占用
>
> 节约线程进行初始化销毁的时间，支持复用
>
> 可以针对性的设置线程数，队列形式，实现拒绝策略等

#### 线程池创建方式，有哪些可以直接使用的线程池类型

> 可以使用Excutor来创建；
>
> 已提供的线程池类型 SinglePool 一个线程，fixPool 固定数目线程，schedulePool 延迟队列的线程池，sychroniazed 不设置线程数，新任务来都新建一个线程

#### 线程池参数

> 核心线程数
>
> 最大线程数
>
> 线程存活时间和单位
>
> 线程工厂
>
> 拒绝策略

#### 任务来时线程池的逻辑

> 当任务来时，有空闲的核心线程就取一个执行，没有空闲时，如果当前核心线程数小于设定值，创建一个核心线程执行
>
> 如果核心线程大于等于设定值，就放入队列
>
> 如果队列有界超长了，此时未到达设置的最大线程，就创建一个非核心线程
>
> 如果达到了最大线程，就执行拒绝策略

#### 拒绝策略都有哪些

> 默认reject 丢弃抛异常
>
> 丢弃不抛异常
>
> 替换队列尾部元素
>
> 自定义的策略（继承reject，增加日志输出报警之类的）

#### 如何估算线程数目

> 如果是cpu密集型，设定n+1~2n
>
> 如果是IO密集型，可以设定2n~n/(1-负载因子0.8或0.9)

#### Queue类型和特点

> ArrayBlockedQueue
>
> LinkedBlockedQueue
>
> DelayQueue
>
> SychronaizedQue ?

## JVM

#### JVM内存结构

> metaspace 永久区
>
> 本地方法栈
>
> JVM栈
>
> 堆
>
> 计数器

#### 堆划分

> 主要划分为新生代和老年代
>
> 新生代分eden区和survivor区，survivor有两块

#### 垃圾回收机制

>新生代MinorGC
>
>老年代FullGC

#### 回收器类型

> 串行回收器 单线程执行
>
> 并行回收器 多线程执行
>
> praiell 保障吞吐量，增加GC频次，缩短GC时间
>
> CMS回收器
>
> G1回收器

#### 年轻代、老年代使用的哪种回收算法？过程？

> 年轻代使用复制算法，扫描eden区和survivor1，将存活对象移到survivor2，清空eden和survivor2，下次交替进行
>
> 老年代使用CMS回收器，用标记清除算法

#### CMS回收器执行过程

> 初始标记 找到GCRoots直接引用的对象标记存活，期间会STW
>
> 并发标记 扫描引用链上的对象进行标记，这期间不STW，系统线程可以同步运行
>
> 二次标记 扫描上一个期间系统线程创建的新对象是否存活，期间STW
>
> 清理 把所有未标记的进行清理，期间不STW

#### FullGC都在什么时候触发？

> 在每次进行MinorGC之前，会检查当前老年代的剩余连续可用空间是否大于本次预估要进入老年代存活对象大小或大于历次minorGC进入老年代大小的平均值，如果大于就进行MinorGC，否则进行FullGC
>
> MinorGC后要移入老年代对象的大小大于老年代的可用空间，会再进行一次FullGC，如果还是不够就会出现内存溢出
>
> 当老年代的对象占用大于设置的参数比例时，会进行FullGC

#### MinorGC如何进行的，内部有什么逻辑

> 当Eden快满的时候，会触发MinorGC
>
> 在进行MinorGC时，如果Eden区和survivor1区扫描后存活对象大于survivor区，直接进入老年代
>
> 动态年龄跑判断，如果扫描对象年龄1+2+...n的占用大小超过survivor区大小的50%，会把所有年龄大于n的对象移到老年代
>
> 大对象会直接进入老年代

#### 频繁FullGC的可能原因

> survivor区设置的太小了，MinorGC后存活对象都直接进老年代，导致老年代很快被占满
>
> 设置的老年代使用占比限定太小了
>
> 整体内存分配过小，老年代空间设置的太小

#### OOM都可能发生在哪些区域和可能原因

> metaspace 永久代  加载了许多class进去，超过了永久代设置的大小
>
> jvm栈  Stack 方法调用栈过深，一般是出现了bug，递归调用未退出等等
>
> 堆空间 HeapOutOfMemory 可能是发生内存泄漏等等

#### G1回收器解析，什么场景可以使用G1

> G1回收器可以设定预期清理时间，会把GC的时间限定在该范围内
>
> G1把堆空间划分成多个region，跟踪计算每个region的空间占用和预计清理时间，在进行GC的时候，会根据预期时间来选取执行清理的region
>
> G1适用于内存比较大机器，内存大老年代大，用CMS回收器FullGC时间较长

#### GCRoots都有哪些

> 类的静态变量
>
> 方法的临时变量

#### JVM线上排查常用命令

> jps或ps -ef|grep java命令，查看进程id
>
> jstat -gc 1000 10，查看下最近的内存使用情况，里面包含了新生代老年代的空间、MinorGC和FullGC的次数和耗时等
>
> jmap -dump 生成jump文件，排查一下是否有内存泄漏或大量对象等

#### 引用类型

> 强 被GCRoots引用的对象，不会被垃圾回收
>
> 软 Refrence包裹的对象，在即将发生内存溢出的时候回收
>
> 弱 会在下一次GC的时候回收
>
> 虚 回收的时候会提醒

#### 类加载机制过程

> 加载 - 找到class文件读到内存中
>
> 验证 - 检查文件的完整性是否被篡改等
>
> 解析 - 生成静态变量等
>
> 准备 - 划分内存空间
>
> 初始化 - 给变量赋初值
>
> 使用
>
> 销毁

#### 类加载器都有哪些

> 启动类加载器 BootStrapClassLoader
>
> 扩展类加载器       ExctClassLoader
>
> 应用程序类加载器
>
> 自定义累加载器

#### 双亲委派模型定义

> 某个类执行加载，会先交由其父类尝试，一直到最顶层，如果不能再交还给其子类进行尝试
>
> 保证类都由相同的加载器加载，保证生成的类对象定义相同

## Redis

### 1、基础

#### SDS

> 定义SDS结构，当前长度，剩余可用长度，存储数组
>
> 1、C语言需要遍历数组，根据’\0‘空字符来计算长度，SDS直接取当前长度
>
> 2、当有新值放入时，可以根据剩余可用长度来进行扩容，也可以动态的缩容
>
> 3、redis会存图片类、语音类的数据，转成数据流里可能会有空字符情况

#### 基础数据类型都有哪些

> String
>
> list   当数据少的时候，用连续的内存空间组成ziplist，当数据量大的时候，多个ziplist连接形成quicklist，减少内存碎片
>
> map 也是数组和链表的形式，跟java不同的是，扩容的时候是渐进性hash，就是复制出一个新的hashmap，逐步的迁移，期间这两个map都对外提供读
>
> set 
>
> sortedset  skiplist形式，多层级的链表

#### Geo、HyperLogLog

> geo 存储地图的经纬度，可以支持计算范围，距离；二刀法，切割平面，形成一串二进制数字和经纬度映射
>
> hyperloglog是 提供了不精准的排重计数

#### bitmap

> byte数组，根据下标进行占位判断是否存在

#### 布隆过滤器

> byte数组形式，会用多个无偏的hash函数计算后对长度取余，计算得出多个下标置为1
>
> 如果有key计算后发现这些位置都为1，说明可能存在，有不为1的就说明一定不存在

#### PubSub

> 消息发布通知结构，不支持数据恢复

### 2、服务

#### 线程模型

> 一个io多路复用线程处理连接
>
> 一个线程处理redis命令

#### 淘汰机制

> 定时淘汰  redis每秒会在所有设置了过期时间的key中抽取20个，把过期的淘汰了，如果过期key的比例超过一半，他就会再次抽20个，最多n次
>
> 惰性淘汰 当这个key发生读写的时候，检查是否过期，如果过期就清除

#### 过期策略

> rejection  空间不够拒绝，抛异常
>
> allkeys-random 全量key随机
>
> allkeys-lru  全量key移除最少使用的
>
> volatile-random 设置了过期时间key里随机
>
> volatile-ttl  设置了过期时间key里移除剩余时间最少的
>
> volatile-lru 设置了过期时间key里移除最近最少使用的

#### 持久化机制

> RDB fork一个子进程，对当前内存数据生成一份快照，以二进制的文件形式存储
>
> AOF 命令的append-only形式增量的添加生成一份文件

#### COW

> RBD期间，如果有写操作，会对该内存页进行拷贝后生成快照

#### aof瘦身

> aof文件过大的时候，会进行一个瘦身操作，就是再生成一份新的aof文件，然后把当前内存数据转化成redis的命令写到新的aof文件，写完再追加这期间发生的增量redis命令，生成完之后替换旧的aof文件

#### 数据恢复方式

> 如果同时开启了rdb和aof机制，服务重启时会优先重放aof文件，aof里的数据更完整
>
> 4.0以后是混合恢复，就是他的文件会包含rdb和aof命令

#### 主从同步原理

> master会维护一份数据，包含backlog同步数据信息，offset同步进度标记，master runid主节点标识
>
> slave也会记录offset和master runid，通过对比master runid和offset来决定是进行全量同步还是增量同步
>
> 当slave首次连接master时，会进行全量同步，后续进行增量同步
>
> master会有一个类似于环形队列这种存储要同步的命令，当同步时延较大时，会采用RDB文件同步，会存在无盘操作，就是生成RDB文件不写磁盘直接通过连接发送出去

#### 哨兵主从切换及选举机制

> 当一个哨兵节点发现master挂了，给他标记成sdown，当所有哨兵都认为master挂了，会把sdown转为odown
>
> 判定odwon后，开始执行选举
>
> 选举投票优先级，slave跟master断开连接时间越短优先级越高；offset越大优先级越高，master runid越大优先级越高
>
> 当某个slave节点超过半数投票，可以把他切换成master
>
> 由一个哨兵节点开始尝试切换，如果切换失败，sentinel集群冷却n秒钟，再由下一个哨兵节点尝试切换，如果切换成功，会从新的master节点取得一个version，发布到监听集群的pubsub频道，其他节点通过订阅频道对比version来判断是否更新集群信息

#### 脑裂如何解决

> redis有两个参数 
>
> 限定master下的最小slave节点个数
>
> 主从同步延迟不大于n秒
>
> 当不满足时，就会阻止master节点的写操作，减少数据的差异

#### 集群类型

> redis远程的集群方案
>
> redis-cluster
>
> 划分多个slot槽分不到多个redis节点上，默认是16384个槽，每个节点都维护一份槽和节点的映射表
>
> 客户端连接任一个节点，根据key计算出槽位置，如果在当前节点上，就返回数据，如果不在就返回重定向响应
>
> 
>
> 三方的codis，存在一个proxy代理维护映射表，存在可用性问题，可以设置多个proxy提供服务

## MySQL

#### mysql的命令执行过程

> 命令经过解析器优化器后开始执行，如果当前内存中的bufferpool中没有目标值，就从磁盘上加载，
>
> 如果有先将旧值写入到undolog，再修改bufferpool中的缓存值
>
> 修改后，在redobuffpool也放一份，后续会写入磁盘文件生成redolog
>
> 事务commit提交完成后，生成binlog，在redolog中记录命令已commit的标记

#### BufferPool

> 划分了多个bufferpool优化内存使用

#### lru链表

#### free链表

### 1、事务

#### ACID

#### 引擎类型

> mysim  不支持事务，一般用于支持报表读
>
> innodb，支持事务，支持行级锁表级锁

#### innodb隔离级别及可能出现的问题

> 读未提交，会出现不可重复读、脏读、幻读
>
> 读已提交，会出现不可重复读，幻读
>
> 可重复读，会出现幻读
>
> 串行

#### 什么是不可重复读

> 一个事务读取两次，结果不同

#### 什么是脏读

> 一个事务，能读取到其他事务修改但还未提交的内容

#### 什么是幻读

> 一个事务第一次读到了某些数据，再一次读取时数据被其他事务删除或增加了

#### MVCC原理

> 每个事务都维护一份readview，里面包含了当前事务id（trx_id），下一时刻最大事务id（trx_max_id），当前时刻最小id（trx_min_id）和进行中的事务id数组[t1, t2, t3...]
>
> 数据项有个字段会存储最近一次的事务id
>
> 通过对比事务id和数据项里的id，根据对比高低水位来判断是否可见

#### 高低水位判断

> 当数据项里的trxid 大于当前事务记录的trx_max_id，说明是在该事务发生后变动的，那么该条不可见，需要去undolog中查找
>
> 当小于trx_min_id时，说明时在该事务发生前处理的，该条可见
>
> 当大于trx_min_id，小于trx_max_id时，去数组中查找，如果不存在说明已提交该条可见，否则不可见

### 2、索引

#### 索引结构

> B+Tree，只有叶子节点存储数据

#### 索引类型

> 主键索引，聚簇索引
>
> 唯一索引
>
> 联合索引，最左原则
>
> 前缀索引

#### 什么是聚簇索引

> 聚簇索引叶子节点即为数据页，非聚簇索引叶子节点存储数据页的指针

#### 联合索引最左原则

> 查询时要从联合索引字段的左边开始才能用到索引

#### 建表时如果没有指定主键？

> 如果没有指定主键，会选一个非null的字段来建立索引
>
> 如果没有非null的，会用行号来建立

#### SQL优化

> 查询时尽量使用到索引，减少数据扫描的范围
>
> 避免使用*查询
>
> 查询条件中避免使用not in、not exist等
>
> 避免使用like %a
>
> 避免使用or，or的每个条件都需要触发索引，可以缓存in或union
>
> 避免在条件的左侧加函数转化
>
> 避免存在隐式转换，比如说查询char类型，但是传入的参数值是1

#### explain参数

>explain sql查看命中索引状态
>
>主要观察的几个参数
>
>type 查询类型，主查询还是联合查询
>
>ref 可能用到的索引
>
>查询的类型，all全表、index主键索引、range范围、uniqe唯一索引
>
>扫描行数

## 分布式

#### 分布式事务种类

> 两阶段提交，存在一个协调者，分两个阶段，准备 和 提交；
>
> 准备：所有参与者向协调者上报precommit状态，当所有上报完毕后进入第二阶段
>
> 提交：状态全部ok通知所有参与者执行commit，如果有一个不ok就通知执行rollback，通知失败会一直尝试通知
>
> 
>
> 三阶段提交，在两阶段基础上，增加一个准备阶段，减少参与者的资源锁定时间
>
> 预备：询问所有参与者是否都准备好进行precommit，所有参与者都回复预备好，通知进行下一阶段
>
> 准备：
>
> 提交
>
> 
>
> 本地事务表
>
> 在同一个事务中进行数据变动和插入一条本地表记录，保证表记录存在时，数据就变动成功
>
> 事务提交成功，调用下一个操作，如果下一个操作执行成功，将本地信息表中的记录修改为已完成，如果未成功进行重试
>
> 定时任务扫描本地表，发现有未完成的记录就重新发起调用
>
> 
>
> TCC事务，入侵性比较大，需要实现tcc三个方法来进行修改提交回滚，可能需要在表中加字段来存储旧值
>
> TCC事务框架 tcc-transaction
>
> try  修改
>
> commit 保存
>
> cancel 回滚
>
> 
>
> 可靠消息最终一致性
>
> 基于消息队列，precommit后向队列发送一条事务消息，该事务消息对消费者不可见
>
> 发送成功接收到ack后，执行commit，向mq发送确认
>
> mq收到确认后将该事务消息推送给消费者消费
>
> 如果mq超时未收到反馈，会主动callback生产者，检查该事务消息是否成功或失败，成功即发给消费者，失败直接丢弃
>
> 
>
> 最大努力通知型
>
> 就是事务执行完成一直通知，直到成功

## MQ

#### 为什么使用消息队列

> 解耦 降低系统间的耦合程度
>
> 异步
>
> 削峰

#### 使用时要注意什么

> 注意保证消息留档，支持恢复
>
> 注意消费者向的操作幂等

#### 如何保证消息传输的可靠性

> 开启conform机制
>
> 开启主动ack机制

#### 如何保证消息传输的时序性

>根据key路由到相同的节点消费
>
>通过增加消息id来指定顺序

#### 队列积压如何解决

>先检查积压原因修复
>
>可以适当增加消费者
>
>写入日志，低峰期进行补单

#### 如何保证消息不被重复消费

> 消费者增加幂等校验

#### 如何防止高并发情况下消费者内存溢出

> 消费者端开启最大拉取数目

### 1、Kafka

#### kafka如何做到的高吞吐低延迟

> 一个topic划分成多个partion，
>
> leader-follower，保证集群可用性
>
> 维护了一个ISR信息，当前和leader节点保持同步的follower信息，只要leader和一个follower节点完成写操作即可

#### kafka是如何优化网络通信性能的

> 相同的topic信息会放到一个batch中，多个batch通过一个连接发送出去

#### kafka是如何优化GC的

>内部初始化多个batch，每次取用放回，减少创建销毁过程

#### kafka的acks参数对消息持久化的影响

>

#### 内存缓冲里的batch是如何判定可以发送的

### 2、RabbitMQ

#### rabbitmq支持的exchange路由模式

>direct
>
>fanout
>
>topic
>
>header

#### 如果你设计一个消息中间件，该考虑哪写内容

>多节点高可用
>
>消息存档可恢复
>
>消息ack保证可达
>
>内存缓存GC优化

#### 延迟消息队列

> 比如说待支付订单关闭，定时任务一直扫不是一个好方案，可以订单生成的时候写入延迟队列，超过n分钟后去DB查询一下支付状态

## RPC

### 1、Dubbo

#### dubbo的节点角色

> provider
>
> consumer
>
> register
>
> minotor

#### dubbo服务注册发现的流程图

> consumer 和 provider启动后向register注册，发布接口或拉取节点接口信息
>
> 定时向monitor上报调用次数和相应时间
>
> register远程调用consumer

#### dubbo支持哪些注册中心

> 默认zookeeper，支持nacos等

#### 负载均衡方式

>轮询
>
>一致性hash
>
>随机
>
>权重比

#### 容错机制

> fail       自动切换尝试下一个节点，支持配置重试次数
>
> failfast 快速失败

### 2、Feign

> dubbo支持多种协议，默认dubbo协议，使用netty框架，TCP连接传输数据，适合小数据量，提供者远少于消费者的情况
>
> feign是通过http调用，短连接

## 缓存

#### 说一下缓存穿透、缓存击穿、缓存雪崩

> 缓存穿透， 缓存不存在，直接查数据库，同时数据库中也没有数据
>
> 限流、校验正确性、生成不存在的缓存
>
> 
>
> 缓存击穿，查询时候，缓存失效了，请求直接查库
>
> 定时续期、热点数据不设置过期时间
>
> 
>
> 缓存雪崩，大量key在同一时刻失效
>
> 增加随机时间，数据分散到集群的多个节点

#### 热点key如何解决

> 增加系统缓存，减少流入到redis的量
>
> 集群多个节点都生成热点key路由查询

#### 如何保证缓存数据一致性

>先修改数据库，再删除缓存
>
>
>
>异步缓存双删
>
>先删除缓存，再修改数据库，等待几秒再删除缓存；可以加到队列进行异步删除

#### 为什么是删除缓存而不是更改缓存

>缓存可能是一系列计算后的结果，影响效率
>
>缓存可能不是热点数据，没必要每次都修改，读时懒加载即可

#### 常见的限流实现方式

> hystrix、sentinel等线程的框架做限流
>
> 利用redis sortedset做滑动窗口式限流
>
> 漏斗限流
>
> 令牌桶限流

## Spring

#### bean的生命周期

> bean加载
>
> 创建bean实例
>
> 检查是否实现了aware类型的接口
>
> 实例参数初始化
>
> 是否实现beanpostprocesser内方法
>
> init方法
>
> 使用
>
> destroy方法

#### bean的作用域

> singleton 单例
>
> prototype 每次请求创建一个
>
> cookies 每次请求创建一个，仅在cookies范围有效
>
> session

#### 依赖注入方式

> 通过构造方法
>
> 通过setter

#### AOP如何实现

> AOP就是把一些不属于业务范围的，又会被业务调用到的功能，比如说访问日志、权限校验等，抽取成公共的方法，通过切面的方式，减少代码的冗余，扩展性、维护性强

#### AOP的advice类型

>before、after、around、afterreturning、afterthrowing

#### 如何解决循环依赖

> bean实例化分两步，第一步创建bean实例，第二部对实例内变量初始化
>
> 提供了三级缓存机制，创建好的bean实例会加到二级缓存中，其他依赖者会从二级缓存中获取实例，当完成变量初始化后会加到一级缓存中，后续真正使用的是这里对象
>
> 
>
> 可以通过lazy注解或DepensOn注解来控制实例进度

#### spring的事务类型、传播机制

> default 同数据库一致
>
> 读未提交、读已提交、可重复度、串行

#### spring的事务传播机制

> 当前支持事务情况
>
> 如果当前有事务加入该事务，没有则创建一个新事务
>
> 如果当前有事务加入该事务，没有则以非事务方式运行
>
> 如果当前有事务加入该事务，没有则抛异常
>
> 
>
> 当前不支持事务情况
>
> 以非事务方式运行，如果有事务则挂起
>
> 以非事务方式运行，如果有则抛异常

spring自动装载机制

> 通过开启@EnableAutoConfiguration配置，把配置@Configuration类下的@bean加载到spring容器内
>
> 外部的xml文件，在方法中读取，通过bean注解的方式加载进来

## 其他

#### 网络模型

>应用层
>
>表现层                                                                     
>
>会话层         
>
>传输层
>
>网络层
>
>数据链路层
>
>物理层

#### TCP和UDP区别

>TCP 长连接
>
>UDP 短连接

#### TCP的三次握手和四次挥手

>创建连接时
>
>客户端发起请求 发送syn=1,seq = x
>
>服务端接收请求，将syn=1,seq=y,ack=x+1，返回给客户端
>
>客户端接收到，seq=x+1, ack=y+1
>
>
>
>断开连接时
>
>全双工，双方都需要进行断开

#### 为什么需要三次握手

> 防止多次syn连接请求，旧的请求先返回，这样可以再次发送rst来取消旧的syn请求

#### 为什么需要四次握手

> TPC是全双工模式，双方都要进行断开、确认流程

#### 为什么断开需要等待两个time_wait

> 如过未收到ack反馈，可以进行重发，继续等待一个timewait
>
> 使上一个连接的消息过期

#### TCP拥塞控制

> 控制请求的发送速度
>
> 慢开始	刚开始假设发送一个请求，接收ack后下次一次性发送2个请求，再下一次发送4个，这样一直递增
>
> 拥塞控制 当有ack未收到时，会把重新从1开始发送，然后每次增加1个

#### redis和zookeeper分布式锁的优缺点

>redis锁通过lua脚本实现，集群模式下，如果master挂了，锁还未同步到slave，可能出现重复加锁问题
>
>redis通过redlock机制解决，就是加锁时向所有节点都创建锁，每个加锁行为都有超时设定，只有半数以上的节点加锁成功才认为成功，否则认为失败执行清除
>
>
>
>zookeeper分布式锁
>
>利用永久节点和临时顺序节点实现
>
>先创建一个永久节点，当加锁时在这个永久节点下创建一个临时顺序节点，有其他参与者加锁时，再在下面创建新的临时顺序节点，同时监听上一个节点状态，如果上一个节点被删除了，他就尝试获取

#### BIO、NIO、IO多路复用、异步IO

> BIO：阻塞型io，请求阻塞等待线程执行完
>
> NIO：非阻塞io，先询问是否有空闲资源，如果有再进行IO操作
>
> 异步IO：发送完，等待回调

#### IO多路复用原理

> IO连接注册到channel上，交由线程来轮询处理
>
> 存在三种实现方式
>
> select，存在连接数大小限制，数组式，最大1024个
>
> poll，无大小限制，链表式
>
> epoll，只针对当前有IO行为发生的连接进行轮询，生成callback，只轮询有callback的提高性能

#### 零拷贝

> 数据从
>
> 磁盘 - os cache - 用户cache - socket - 网卡发送
>
> 变为
>
> 磁盘 - os cache - 网卡发送
>
> 省略了从系统向应用缓存转移的步骤，只给socket同步一个描述符接收响应

## 算法

#### 二分查找



#### 快排



#### 冒泡排序



#### 贪心、动态规划



## 秒杀

### 架构

#### 1、静态页面缓存

> 1、秒杀数据通过模板提前生成静态页面，放到cnd节点缓存分散压力

#### 2、安全保证机制

>1、静态页面中引入一个js文件，文件内包含活动是否开始标记以及下单的url，不缓存这个js文件，一直向后端请求，当活动快开始时，提前修改文件内标记
>
>2、客户端会从服务端申请一个随机字符串的md5加密值，访问url时传过来，后端校验
>
>3、同一个用户单位时间内多次请求，统一走缓存，返回同一个页面
>
>4、大量请求同一时间段查询同一个商品，做页面级缓存

#### 3、nginx

>秒杀系统独立的nginx服务，接入风控系统，对用户账户校验（大数据对账户进行分析，打上标签）

#### 4、限流

> 1、前端限流，未开始不可点击，设置连点次数
>
> 2、限制
>
> 3、后端设置活动开始标记，当库存售光时，直接关闭秒杀

#### 5、缓存预热

>

#### 6、秒杀资源独立

> 独立的服务、redis、mysql集群

### 类型

#### 单sku

> 秒杀商品通过redis多个节点缓存一份库存key，

#### 多sku



## 分库分表

### 垂直拆分

> 按维度拆分独立的数据库集群实例

### 水平拆分

优点：多个数据库分担压力

缺点：破坏了原有数据库事务，分布式事务需要考虑性能问题

> 

### 分库分表后多维度查询如何解决

##### 淘宝做法

> 订单号后    

#### 1、冗余

> 以新维度再生成一份分表数据，提供查询

#### 2、Elasticsearch二级索引

> 构建维度到id的二级索引，先通过维度查到id，再去mysql查id

##### mysql和es怎么保证数据一致

> 订阅binlog，写入es
>
> es写入失败，记录，定时任务扫描进行补偿

3、

>

### 递归如何保证不进行太多的压栈操作

使用尾递归

#### 尾递归如何优化

计算值利用全局的中间变量存储，重复利用一个递归函数的栈帧

